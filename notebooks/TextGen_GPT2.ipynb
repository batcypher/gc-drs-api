{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TextGen_GPT2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISkMXBIacqfV",
        "outputId": "5245f0d0-f70f-4a5c-9904-7b8e463d7271"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6njQAJ0dfuj"
      },
      "source": [
        "!pip install pytorch-transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68zEbVOBcuEr",
        "outputId": "ac07a7fd-abe4-4f5e-bf9c-652eaad8324a"
      },
      "source": [
        "import torch\n",
        "from pytorch_transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading GPT2 tokenizer...')\n",
        "output_dir = '/content/drive/MyDrive/gpt2_textgen_model'\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(output_dir)\n",
        "model = GPT2LMHeadModel.from_pretrained(output_dir)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading GPT2 tokenizer...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-RVIPfBddIl"
      },
      "source": [
        "sentence = \"what is the fastest car in the\"\n",
        "tokens = tokenizer.encode(sentence)\n",
        "tokens_tensor = torch.tensor([tokens])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "co1OuUOId3_B"
      },
      "source": [
        "tokens_tensor = tokens_tensor.to('cpu')\n",
        "model.to('cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMtSuNMBd49B"
      },
      "source": [
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUQBjX8Ld8Qv"
      },
      "source": [
        "with torch.no_grad():\n",
        "    outputs = model(tokens_tensor)\n",
        "    predictions = outputs[0]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAHIW8lXeAAF"
      },
      "source": [
        "predicted_index = torch.argmax(predictions[0,-1,:]).item()\n",
        "predicted_text = tokenizer.decode(tokens + [predicted_index])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "AHwciesieEw2",
        "outputId": "9a4f6b2c-13b9-478e-b601-4b0b341c6cd5"
      },
      "source": [
        "predicted_text"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' what is the fastest car in the world'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEpOlhIGeGkS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}